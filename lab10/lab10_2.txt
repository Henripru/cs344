a. Adagrad modifies the learning rate individually for each coefficient in the model. It is supposed to work particually well for convex problems

Task 1

RMSE 72.01

def normalize_linear_scale(examples_dataframe):
  result = pd.DataFrame()
  result["latitude"] = linear_scale(examples_dataframe["latitude"])
  result["longitude"] = linear_scale(examples_dataframe["longitude"])
  result["housing_median_age"] = linear_scale(examples_dataframe["housing_median_age"])
  result["total_rooms"] = linear_scale(examples_dataframe["total_rooms"])
  result["total_bedrooms"] = linear_scale(examples_dataframe["total_bedrooms"])
  result["population"] = linear_scale(examples_dataframe["population"])
  result["households"] = linear_scale(examples_dataframe["households"])
  result["median_income"] = linear_scale(examples_dataframe["median_income"])
  result["rooms_per_person"] = linear_scale(examples_dataframe["rooms_per_person"])
  return result

_ = train_nn_regression_model(
    my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.005),
    steps=2000,
    batch_size=50,
    hidden_units=[10, 10],
    training_examples=normalized_training_examples,
    training_targets=training_targets,
    validation_examples=normalized_validation_examples,
    validation_targets=validation_targets)

Task 2

adagrad RMSE training 69.21
adagrad RMSE validation 68.49

_, adagrad_training_losses, adagrad_validation_losses = train_nn_regression_model(
    my_optimizer=tf.train.AdagradOptimizer(learning_rate=0.5),
    steps=500,
    batch_size=100,
    hidden_units=[10, 10],
    training_examples=normalized_training_examples,
    training_targets=training_targets,
    validation_examples=normalized_validation_examples,
    validation_targets=validation_targets)

adam training RMSE 70.38
adam validation RMSE 69.95

_, adam_training_losses, adam_validation_losses = train_nn_regression_model(
    my_optimizer=tf.train.AdamOptimizer(learning_rate=0.009),
    steps=500,
    batch_size=100,
    hidden_units=[10, 10],
    training_examples=normalized_training_examples,
    training_targets=training_targets,
    validation_examples=normalized_validation_examples,
    validation_targets=validation_targets)

Task 3

RMSE training 67.73
RMSE validation 67.08

def normalize(examples_dataframe):
  """Returns a version of the input `DataFrame` that has all its features normalized."""
  result = pd.DataFrame()

  result["households"] = log_normalize(examples_dataframe["households"])
  result["median_income"] = log_normalize(examples_dataframe["median_income"])
  result["total_bedrooms"] = log_normalize(examples_dataframe["total_bedrooms"])
  
  result["latitude"] = linear_scale(examples_dataframe["latitude"])
  result["longitude"] = linear_scale(examples_dataframe["longitude"])
  result["housing_median_age"] = linear_scale(examples_dataframe["housing_median_age"])

  result["population"] = linear_scale(clip(examples_dataframe["population"], 0, 5000))
  result["rooms_per_person"] = linear_scale(clip(examples_dataframe["rooms_per_person"], 0, 5))
  result["total_rooms"] = linear_scale(clip(examples_dataframe["total_rooms"], 0, 10000))

  return result

normalized_dataframe = normalize(preprocess_features(california_housing_dataframe))
normalized_training_examples = normalized_dataframe.head(12000)
normalized_validation_examples = normalized_dataframe.tail(5000)

_ = train_nn_regression_model(
    my_optimizer=tf.train.AdagradOptimizer(learning_rate=0.15),
    steps=1000,
    batch_size=50,
    hidden_units=[10, 10],
    training_examples=normalized_training_examples,
    training_targets=training_targets,
    validation_examples=normalized_validation_examples,
    validation_targets=validation_targets)